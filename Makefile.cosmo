# Cosmopolitan Libc Makefile for llama-server

CC = $(PWD)/cosmocc/bin/cosmocc
CXX = $(PWD)/cosmocc/bin/cosmoc++

INCLUDES = -Ivendor/llama.cpp/include -Ivendor/llama.cpp/ggml/include -Ivendor/llama.cpp/common -Ivendor/llama.cpp/ggml/src -Ivendor/llama.cpp/ggml/src/ggml-cpu -Ivendor/llama.cpp/src -Ivendor/llama.cpp/vendor -Ivendor/llama.cpp/tools/mtmd
CFLAGS = -O3 -mcosmo $(INCLUDES) -D_XOPEN_SOURCE=700 -D_GNU_SOURCE -DGGML_USE_CPU -D__linux__ -DGGML_VERSION=\"cosmo\" -DGGML_COMMIT=\"cosmo\"
CXXFLAGS = -O3 -mcosmo -std=c++17 $(INCLUDES) -D_XOPEN_SOURCE=700 -D_GNU_SOURCE -DGGML_USE_CPU -D__linux__ -DGGML_VERSION=\"cosmo\" -DGGML_COMMIT=\"cosmo\"

# GGML Sources
GGML_SRC = \
    vendor/llama.cpp/ggml/src/ggml.c \
    vendor/llama.cpp/ggml/src/ggml-alloc.c \
    vendor/llama.cpp/ggml/src/ggml-backend.cpp \
    vendor/llama.cpp/ggml/src/ggml-backend-reg.cpp \
    vendor/llama.cpp/ggml/src/ggml-quants.c \
    vendor/llama.cpp/ggml/src/ggml-threading.cpp \
    vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c \
    vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp \
    vendor/llama.cpp/ggml/src/ggml-cpu/quants.c \
    vendor/llama.cpp/ggml/src/ggml-cpu/repack.cpp \
    vendor/llama.cpp/ggml/src/ggml-cpu/hbm.cpp \
    vendor/llama.cpp/ggml/src/ggml-cpu/traits.cpp \
    vendor/llama.cpp/ggml/src/ggml-cpu/binary-ops.cpp \
    vendor/llama.cpp/ggml/src/ggml-cpu/unary-ops.cpp \
    vendor/llama.cpp/ggml/src/ggml-cpu/vec.cpp \
    vendor/llama.cpp/ggml/src/ggml-cpu/ops.cpp

# Llama Sources
LLAMA_SRC = \
    vendor/llama.cpp/src/llama.cpp \
    vendor/llama.cpp/src/llama-vocab.cpp \
    vendor/llama.cpp/src/llama-grammar.cpp \
    vendor/llama.cpp/src/llama-sampler.cpp \
    vendor/llama.cpp/src/unicode.cpp \
    vendor/llama.cpp/src/unicode-data.cpp \
    vendor/llama.cpp/src/llama-model-loader.cpp \
    vendor/llama.cpp/src/llama-kv-cache.cpp \
    vendor/llama.cpp/src/llama-context.cpp \
    vendor/llama.cpp/src/llama-chat.cpp \
    vendor/llama.cpp/src/llama-adapter.cpp \
    vendor/llama.cpp/src/llama-arch.cpp \
    vendor/llama.cpp/src/llama-batch.cpp \
    vendor/llama.cpp/src/llama-hparams.cpp \
    vendor/llama.cpp/src/llama-mmap.cpp \
    vendor/llama.cpp/src/llama-model.cpp \
    vendor/llama.cpp/src/llama-quant.cpp

# Common Sources
COMMON_SRC = \
    vendor/llama.cpp/common/common.cpp \
    vendor/llama.cpp/common/console.cpp \
    vendor/llama.cpp/common/sampling.cpp \
    vendor/llama.cpp/common/peg-parser.cpp \
    vendor/llama.cpp/common/json-schema-to-grammar.cpp \
    vendor/llama.cpp/common/json-partial.cpp \
    vendor/llama.cpp/common/regex-partial.cpp \
    vendor/llama.cpp/common/speculative.cpp \
    vendor/llama.cpp/common/log.cpp \
	vendor/llama.cpp/common/arg.cpp

# Server Sources
SERVER_SRC = \
    vendor/llama.cpp/tools/server/server.cpp \
    vendor/llama.cpp/tools/mtmd/mtmd-helper.cpp

OBJS = $(GGML_SRC:.c=.o)
OBJS += $(GGML_SRC:.cpp=.o)
OBJS += $(LLAMA_SRC:.cpp=.o)
OBJS += $(COMMON_SRC:.cpp=.o)
OBJS += $(SERVER_SRC:.cpp=.o)

# Helper to filter out source files from OBJS list to get only object files
# This is needed because the variable substitution above doesn't remove the source files from the list if they don't match pattern
OBJS := $(filter %.o,$(OBJS))

all: llama-server.com

llama-server.com: $(OBJS)
	$(CXX) $(CXXFLAGS) -o $@ $(OBJS)

%.o: %.c
	$(CC) $(CFLAGS) -c $< -o $@

%.o: %.cpp
	$(CXX) $(CXXFLAGS) -c $< -o $@

clean:
	rm -f $(OBJS) llama-server.com
